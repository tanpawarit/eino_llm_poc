package main

import (
	"context"
	"errors"
	"fmt"
	"log"
	"os"
	"strings"
	"time"

	"github.com/cloudwego/eino-ext/components/model/openai"
	"github.com/cloudwego/eino/compose"
	"github.com/cloudwego/eino/schema"
	"github.com/joho/godotenv"
)

// main function for running chat model examples
func main() {
	if err := runChatModelExample(); err != nil {
		log.Fatalf("Error running chat model example: %v", err)
	}
}

// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Chat Model Node - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö LLM ‡∏à‡∏£‡∏¥‡∏á
func runChatModelExample() error {
	// Load environment
	if err := godotenv.Load(); err != nil {
		// .env file is optional, just log warning
		log.Printf("Warning: .env file not found or couldn't be loaded: %v", err)
	}

	// Create context with timeout for the entire example
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	apiKey := os.Getenv("OPENROUTER_API_KEY")
	if apiKey == "" {
		return errors.New("OPENROUTER_API_KEY environment variable is required")
	}

	// Validate API key format
	if len(strings.TrimSpace(apiKey)) < 10 {
		return errors.New("OPENROUTER_API_KEY appears to be invalid (too short)")
	}

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á Chat Model
	config := &openai.ChatModelConfig{
		APIKey:  apiKey,
		BaseURL: "https://openrouter.ai/api/v1",
		Model:   "openai/gpt-3.5-turbo",
	}

	model, err := openai.NewChatModel(ctx, config)
	if err != nil {
		return fmt.Errorf("failed to create chat model: %w", err)
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1: Direct Chat Model Node ===
	fmt.Println("=== Direct Chat Model Node ===")
	if err := runDirectChatModel(ctx, model); err != nil {
		return fmt.Errorf("direct chat model example failed: %w", err)
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2: Multi-Role Chat Model ===
	fmt.Println("\n=== Multi-Role Chat Model ===")
	if err := runMultiRoleChatModel(ctx, model); err != nil {
		return fmt.Errorf("multi-role chat model example failed: %w", err)
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3: Chat Model with Context ===
	fmt.Println("\n=== Chat Model with Context ===")
	if err := runChatModelWithContext(ctx, model); err != nil {
		return fmt.Errorf("contextual chat model example failed: %w", err)
	}

	return nil
}

// validateMessages validates input messages
func validateMessages(messages []*schema.Message) error {
	if len(messages) == 0 {
		return errors.New("messages cannot be empty")
	}

	for i, msg := range messages {
		if msg == nil {
			return fmt.Errorf("message at index %d is nil", i)
		}
		if strings.TrimSpace(msg.Content) == "" {
			return fmt.Errorf("message at index %d has empty content", i)
		}
		if msg.Role == "" {
			return fmt.Errorf("message at index %d has empty role", i)
		}
	}

	return nil
}

// Direct Chat Model Node
func runDirectChatModel(ctx context.Context, model *openai.ChatModel) error {
	graph := compose.NewGraph[[]*schema.Message, *schema.Message]()

	// Chat Model Node ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö messages ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô response message
	chatModelNode := compose.InvokableLambda(func(ctx context.Context, messages []*schema.Message) (*schema.Message, error) {
		// Validate input messages
		if err := validateMessages(messages); err != nil {
			return nil, fmt.Errorf("invalid messages: %w", err)
		}

		fmt.Printf("ü§ñ Chat Model: Processing %d messages\n", len(messages))
		
		// ‡πÅ‡∏™‡∏î‡∏á messages ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
		for i, msg := range messages {
			// Truncate long content for display
			content := msg.Content
			if len(content) > 100 {
				content = content[:100] + "..."
			}
			fmt.Printf("  [%d] %s: %s\n", i+1, msg.Role, content)
		}

		// Create timeout context for LLM call
		llamCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
		defer cancel()

		response, err := model.Generate(llamCtx, messages)
		if err != nil {
			return nil, fmt.Errorf("chat model error: %w", err)
		}

		if response == nil {
			return nil, errors.New("received nil response from chat model")
		}

		fmt.Printf("ü§ñ Response: %s\n", response.Content)
		return response, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° node
	graph.AddLambdaNode("chat_model", chatModelNode)
	graph.AddEdge(compose.START, "chat_model")
	graph.AddEdge("chat_model", compose.END)

	// Compile
	runnable, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
	testMessages := [][]*schema.Message{
		{
			schema.SystemMessage("‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°"),
			schema.UserMessage("‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Eino Graph ‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏´‡∏ô‡πà‡∏≠‡∏¢"),
		},
		{
			schema.UserMessage("Go channel ‡πÉ‡∏ä‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏á?"),
		},
	}

	for i, messages := range testMessages {
		fmt.Printf("\n--- Test %d ---\n", i+1)
		
		// Create timeout for individual test
		testCtx, cancel := context.WithTimeout(ctx, 45*time.Second)
		result, err := runnable.Invoke(testCtx, messages)
		cancel()
		
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}
		
		if result == nil {
			fmt.Printf("Error: received nil result\n")
			continue
		}
		
		fmt.Printf("Final Result: %s\n", result.Content)
	}

	return nil
}

// Multi-Role Chat Model
func runMultiRoleChatModel(ctx context.Context, model *openai.ChatModel) error {
	graph := compose.NewGraph[string, string]()

	// Message Formatter - ‡πÅ‡∏õ‡∏•‡∏á string ‡πÄ‡∏õ‡πá‡∏ô messages ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö role ‡∏ï‡πà‡∏≤‡∏á‡πÜ
	teacherFormatter := compose.InvokableLambda(func(ctx context.Context, input string) ([]*schema.Message, error) {
		messages := []*schema.Message{
			schema.SystemMessage("‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏π‡∏™‡∏≠‡∏ô‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"),
			schema.UserMessage(input),
		}
		fmt.Printf("üë©‚Äçüè´ Teacher Role: Prepared messages for teaching\n")
		return messages, nil
	})

	codeReviewerFormatter := compose.InvokableLambda(func(ctx context.Context, input string) ([]*schema.Message, error) {
		messages := []*schema.Message{
			schema.SystemMessage("‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô Senior Developer ‡∏ó‡∏µ‡πà review code ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏ä‡∏µ‡πâ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"),
			schema.UserMessage(input),
		}
		fmt.Printf("üë®‚Äçüíª Code Reviewer Role: Prepared messages for code review\n")
		return messages, nil
	})

	architectFormatter := compose.InvokableLambda(func(ctx context.Context, input string) ([]*schema.Message, error) {
		messages := []*schema.Message{
			schema.SystemMessage("‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô Software Architect ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏™‡∏π‡∏á ‡∏°‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°"),
			schema.UserMessage(input),
		}
		fmt.Printf("üèóÔ∏è Architect Role: Prepared messages for architecture guidance\n")
		return messages, nil
	})

	// Chat Model Nodes ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö role ‡∏ï‡πà‡∏≤‡∏á‡πÜ
	chatModelNode := compose.InvokableLambda(func(ctx context.Context, messages []*schema.Message) (string, error) {
		// Validate input
		if err := validateMessages(messages); err != nil {
			return "", fmt.Errorf("invalid messages: %w", err)
		}

		// Create timeout for LLM call
		llamCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
		defer cancel()

		response, err := model.Generate(llamCtx, messages)
		if err != nil {
			return "", fmt.Errorf("chat model generation failed: %w", err)
		}

		if response == nil {
			return "", errors.New("received nil response from chat model")
		}

		return response.Content, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	graph.AddLambdaNode("teacher_formatter", teacherFormatter)
	graph.AddLambdaNode("reviewer_formatter", codeReviewerFormatter)
	graph.AddLambdaNode("architect_formatter", architectFormatter)
	graph.AddLambdaNode("teacher_chat", chatModelNode)
	graph.AddLambdaNode("reviewer_chat", chatModelNode)
	graph.AddLambdaNode("architect_chat", chatModelNode)

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á branches ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö role ‡∏ï‡πà‡∏≤‡∏á‡πÜ
	graph.AddEdge(compose.START, "teacher_formatter")
	graph.AddEdge("teacher_formatter", "teacher_chat")
	graph.AddEdge("teacher_chat", compose.END)

	// Compile ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ role
	teacherGraph, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile teacher graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Teacher Role
	fmt.Printf("\n--- Teacher Mode ---\n")
	testCtx, cancel := context.WithTimeout(ctx, 45*time.Second)
	result, err := teacherGraph.Invoke(testCtx, "Goroutine ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?")
	cancel()
	if err != nil {
		fmt.Printf("Teacher mode error: %v\n", err)
	} else {
		fmt.Printf("üë©‚Äçüè´ Teacher: %s\n", result)
	}

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á graph ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Code Reviewer
	reviewerGraph := compose.NewGraph[string, string]()
	reviewerGraph.AddLambdaNode("reviewer_formatter", codeReviewerFormatter)
	reviewerGraph.AddLambdaNode("reviewer_chat", chatModelNode)
	reviewerGraph.AddEdge(compose.START, "reviewer_formatter")
	reviewerGraph.AddEdge("reviewer_formatter", "reviewer_chat")
	reviewerGraph.AddEdge("reviewer_chat", compose.END)

	reviewerRunnable, err := reviewerGraph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile reviewer graph: %w", err)
	}
	fmt.Printf("\n--- Code Reviewer Mode ---\n")
	testCtx, cancel = context.WithTimeout(ctx, 45*time.Second)
	result, err = reviewerRunnable.Invoke(testCtx, "func process(data []string) { for i := 0; i < len(data); i++ { fmt.Println(data[i]) } }")
	cancel()
	if err != nil {
		fmt.Printf("Code reviewer mode error: %v\n", err)
	} else {
		fmt.Printf("üë®‚Äçüíª Code Reviewer: %s\n", result)
	}

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á graph ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Architect
	architectGraph := compose.NewGraph[string, string]()
	architectGraph.AddLambdaNode("architect_formatter", architectFormatter)
	architectGraph.AddLambdaNode("architect_chat", chatModelNode)
	architectGraph.AddEdge(compose.START, "architect_formatter")
	architectGraph.AddEdge("architect_formatter", "architect_chat")
	architectGraph.AddEdge("architect_chat", compose.END)

	architectRunnable, err := architectGraph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile architect graph: %w", err)
	}
	fmt.Printf("\n--- Software Architect Mode ---\n")
	testCtx, cancel = context.WithTimeout(ctx, 45*time.Second)
	result, err = architectRunnable.Invoke(testCtx, "‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö microservices ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö e-commerce")
	cancel()
	if err != nil {
		fmt.Printf("Architect mode error: %v\n", err)
	} else {
		fmt.Printf("üèóÔ∏è Architect: %s\n", result)
	}

	return nil
}

// validateContextInput validates context input parameters
func validateContextInput(input map[string]interface{}) error {
	if input == nil {
		return errors.New("input cannot be nil")
	}

	question, ok := input["question"].(string)
	if !ok || strings.TrimSpace(question) == "" {
		return errors.New("question is required and must be a non-empty string")
	}

	_, ok = input["project_info"].(string)
	if !ok {
		return errors.New("project_info is required and must be a string")
	}

	userLevel, ok := input["user_level"].(string)
	if !ok || strings.TrimSpace(userLevel) == "" {
		return errors.New("user_level is required and must be a non-empty string")
	}

	// Validate user level
	validLevels := map[string]bool{"beginner": true, "intermediate": true, "expert": true}
	if !validLevels[userLevel] {
		return fmt.Errorf("user_level must be one of: beginner, intermediate, expert, got: %s", userLevel)
	}

	return nil
}

// Chat Model with Context
func runChatModelWithContext(ctx context.Context, model *openai.ChatModel) error {
	graph := compose.NewGraph[map[string]interface{}, string]()

	// Context Builder - ‡∏™‡∏£‡πâ‡∏≤‡∏á context ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ
	contextBuilder := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) ([]*schema.Message, error) {
		// Validate input first
		if err := validateContextInput(input); err != nil {
			return nil, fmt.Errorf("invalid context input: %w", err)
		}

		userQuestion := input["question"].(string)
		projectInfo := input["project_info"].(string)
		userLevel := input["user_level"].(string)

		var systemPrompt string
		switch userLevel {
		case "beginner":
			systemPrompt = fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà 
Project Context: %s

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏™‡∏°‡∏≠`, projectInfo)
		case "intermediate":
			systemPrompt = fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
Project Context: %s

‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ best practices`, projectInfo)
		case "expert":
			systemPrompt = fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç
Project Context: %s

‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏•‡∏∂‡∏Å ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á`, projectInfo)
		default:
			systemPrompt = fmt.Sprintf(`Project Context: %s`, projectInfo)
		}

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(userQuestion),
		}

		fmt.Printf("üîß Context Builder: Built context for %s level user\n", userLevel)
		return messages, nil
	})

	// Chat Model Node
	contextualChatModel := compose.InvokableLambda(func(ctx context.Context, messages []*schema.Message) (string, error) {
		// Validate messages
		if err := validateMessages(messages); err != nil {
			return "", fmt.Errorf("invalid messages for contextual chat: %w", err)
		}

		fmt.Printf("ü§ñ Contextual Chat Model: Processing with system context\n")
		
		// Create timeout for LLM call
		llamCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
		defer cancel()

		response, err := model.Generate(llamCtx, messages)
		if err != nil {
			return "", fmt.Errorf("contextual chat model generation failed: %w", err)
		}

		if response == nil {
			return "", errors.New("received nil response from contextual chat model")
		}

		return response.Content, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	graph.AddLambdaNode("context_builder", contextBuilder)
	graph.AddLambdaNode("contextual_chat", contextualChatModel)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges
	graph.AddEdge(compose.START, "context_builder")
	graph.AddEdge("context_builder", "contextual_chat")
	graph.AddEdge("contextual_chat", compose.END)

	// Compile
	runnable, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile contextual graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö context ‡∏ï‡πà‡∏≤‡∏á‡πÜ
	testCases := []map[string]interface{}{
		{
			"question":     "Eino Graph ‡πÉ‡∏ä‡πâ parallel processing ‡∏¢‡∏±‡∏á‡πÑ‡∏á?",
			"project_info": "Go microservices project using Eino for workflow orchestration",
			"user_level":   "beginner",
		},
		{
			"question":     "‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ optimize performance ‡∏Ç‡∏≠‡∏á Graph",
			"project_info": "High-traffic API gateway with complex routing logic",
			"user_level":   "intermediate",
		},
		{
			"question":     "Custom node implementation patterns ‡πÅ‡∏•‡∏∞ memory management",
			"project_info": "Enterprise-grade workflow engine with custom extensions",
			"user_level":   "expert",
		},
	}

	for i, testCase := range testCases {
		fmt.Printf("\n--- Context Test %d (%s level) ---\n", i+1, testCase["user_level"])
		fmt.Printf("Question: %s\n", testCase["question"])
		fmt.Printf("Context: %s\n", testCase["project_info"])

		// Create timeout for individual test
		testCtx, cancel := context.WithTimeout(ctx, 45*time.Second)
		result, err := runnable.Invoke(testCtx, testCase)
		cancel()
		
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}

		fmt.Printf("\nResponse:\n%s\n", result)
		fmt.Println(strings.Repeat("-", 80))
	}

	return nil
}