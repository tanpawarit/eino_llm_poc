package main

import (
	"context"
	"errors"
	"fmt"
	"log"
	"os"
	"strings"
	"time"

	"github.com/cloudwego/eino-ext/components/model/openai"
	"github.com/cloudwego/eino/compose"
	"github.com/cloudwego/eino/schema"
	"github.com/joho/godotenv"
)

// Document represents a document in our knowledge base
type Document struct {
	ID       string            `json:"id"`
	Content  string            `json:"content"`
	Metadata map[string]string `json:"metadata"`
}

// MockRetriever simulates a vector database or document retriever
type MockRetriever struct {
	documents []Document
}

// NewMockRetriever creates a new mock retriever with sample documents
func NewMockRetriever() *MockRetriever {
	return &MockRetriever{
		documents: []Document{
			{
				ID:      "doc1",
				Content: "Eino Graph ‡πÄ‡∏õ‡πá‡∏ô library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á workflow ‡πÅ‡∏ö‡∏ö graph ‡πÉ‡∏ô Go ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ node ‡πÅ‡∏•‡∏∞ edge ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô",
				Metadata: map[string]string{
					"topic":    "eino-graph",
					"language": "thai",
					"type":     "documentation",
				},
			},
			{
				ID:      "doc2",
				Content: "Goroutine ‡πÄ‡∏õ‡πá‡∏ô lightweight thread ‡πÉ‡∏ô Go ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ concurrent programming ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á go func()",
				Metadata: map[string]string{
					"topic":    "goroutine",
					"language": "thai",
					"type":     "tutorial",
				},
			},
			{
				ID:      "doc3",
				Content: "Channels ‡πÉ‡∏ô Go ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á goroutines ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£ 'Don't communicate by sharing memory; share memory by communicating'",
				Metadata: map[string]string{
					"topic":    "channels",
					"language": "thai",
					"type":     "tutorial",
				},
			},
			{
				ID:      "doc4",
				Content: "REST API design principles include using HTTP methods correctly, proper status codes, and following RESTful naming conventions",
				Metadata: map[string]string{
					"topic":    "rest-api",
					"language": "english",
					"type":     "documentation",
				},
			},
			{
				ID:      "doc5",
				Content: "Docker containerization allows applications to run consistently across different environments by packaging code with dependencies",
				Metadata: map[string]string{
					"topic":    "docker",
					"language": "english",
					"type":     "documentation",
				},
			},
			{
				ID:      "doc6",
				Content: "Database indexing improves query performance by creating data structures that speed up data retrieval operations",
				Metadata: map[string]string{
					"topic":    "database",
					"language": "english",
					"type":     "documentation",
				},
			},
		},
	}
}

// Retrieve searches for documents based on query
func (r *MockRetriever) Retrieve(ctx context.Context, query string, limit int) ([]Document, error) {
	if query == "" {
		return nil, errors.New("query cannot be empty")
	}

	if limit <= 0 {
		limit = 3 // default limit
	}

	queryLower := strings.ToLower(query)
	var matches []Document

	// Simple keyword-based matching (in real implementation, this would use vector similarity)
	for _, doc := range r.documents {
		contentLower := strings.ToLower(doc.Content)
		
		// Check if query keywords are in content
		keywords := strings.Fields(queryLower)
		matchCount := 0
		for _, keyword := range keywords {
			if strings.Contains(contentLower, keyword) {
				matchCount++
			}
		}

		// If more than half of keywords match, include document
		if float64(matchCount)/float64(len(keywords)) > 0.3 {
			matches = append(matches, doc)
		}
	}

	// Limit results
	if len(matches) > limit {
		matches = matches[:limit]
	}

	fmt.Printf("üîç Retriever: Found %d documents for query '%s'\n", len(matches), query)
	return matches, nil
}

// main function for running retriever examples
func main() {
	if err := runRetrieverExample(); err != nil {
		log.Fatalf("Error running retriever example: %v", err)
	}
}

// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Retriever Node - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG (Retrieval-Augmented Generation)
func runRetrieverExample() error {
	// Load environment
	if err := godotenv.Load(); err != nil {
		log.Printf("Warning: .env file not found or couldn't be loaded: %v", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	apiKey := os.Getenv("OPENROUTER_API_KEY")
	if apiKey == "" {
		return errors.New("OPENROUTER_API_KEY environment variable is required")
	}

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á Chat Model
	config := &openai.ChatModelConfig{
		APIKey:  apiKey,
		BaseURL: "https://openrouter.ai/api/v1",
		Model:   "openai/gpt-3.5-turbo",
	}

	model, err := openai.NewChatModel(ctx, config)
	if err != nil {
		return fmt.Errorf("failed to create chat model: %w", err)
	}

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á Mock Retriever
	retriever := NewMockRetriever()

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1: Basic RAG Node ===
	fmt.Println("=== Basic RAG Node ===")
	if err := runBasicRAG(ctx, model, retriever); err != nil {
		return fmt.Errorf("basic RAG example failed: %w", err)
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2: Advanced RAG with Context Filtering ===
	fmt.Println("\n=== Advanced RAG with Context Filtering ===")
	if err := runAdvancedRAG(ctx, model, retriever); err != nil {
		return fmt.Errorf("advanced RAG example failed: %w", err)
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3: Multi-Step RAG ===
	fmt.Println("\n=== Multi-Step RAG ===")
	if err := runMultiStepRAG(ctx, model, retriever); err != nil {
		return fmt.Errorf("multi-step RAG example failed: %w", err)
	}

	return nil
}

// Basic RAG Node
func runBasicRAG(ctx context.Context, model *openai.ChatModel, retriever *MockRetriever) error {
	graph := compose.NewGraph[string, string]()

	// Retriever Node - ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
	retrieverNode := compose.InvokableLambda(func(ctx context.Context, query string) ([]Document, error) {
		if strings.TrimSpace(query) == "" {
			return nil, errors.New("query cannot be empty")
		}

		fmt.Printf("üîç Retriever Node: Searching for '%s'\n", query)
		
		documents, err := retriever.Retrieve(ctx, query, 3)
		if err != nil {
			return nil, fmt.Errorf("retrieval failed: %w", err)
		}

		// ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö
		for i, doc := range documents {
			content := doc.Content
			if len(content) > 100 {
				content = content[:100] + "..."
			}
			fmt.Printf("  [%d] %s: %s\n", i+1, doc.ID, content)
		}

		return documents, nil
	})

	// Context Builder - ‡∏£‡∏ß‡∏° context ‡∏à‡∏≤‡∏Å retrieved documents
	contextBuilder := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) ([]*schema.Message, error) {
		query, ok := input["query"].(string)
		if !ok || strings.TrimSpace(query) == "" {
			return nil, errors.New("query is required")
		}

		docs, ok := input["documents"].([]Document)
		if !ok {
			return nil, errors.New("documents are required")
		}

		// ‡∏™‡∏£‡πâ‡∏≤‡∏á context ‡∏à‡∏≤‡∏Å documents
		var contextParts []string
		for _, doc := range docs {
			contextParts = append(contextParts, fmt.Sprintf("- %s", doc.Content))
		}

		context := strings.Join(contextParts, "\n")
		
		systemPrompt := fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• context ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤

Context:
%s

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å context ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô context ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠`, context)

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(query),
		}

		fmt.Printf("üìù Context Builder: Built context with %d documents\n", len(docs))
		return messages, nil
	})

	// Input Combiner - ‡∏£‡∏ß‡∏° query ‡πÅ‡∏•‡∏∞ documents ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
	inputCombiner := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (map[string]interface{}, error) {
		// Input should contain both query and documents from previous nodes
		return input, nil
	})

	// Chat Model Node
	chatModelNode := compose.InvokableLambda(func(ctx context.Context, messages []*schema.Message) (string, error) {
		if len(messages) == 0 {
			return "", errors.New("messages cannot be empty")
		}

		fmt.Printf("ü§ñ RAG Chat Model: Generating response with context\n")
		
		llamCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
		defer cancel()

		response, err := model.Generate(llamCtx, messages)
		if err != nil {
			return "", fmt.Errorf("chat model generation failed: %w", err)
		}

		if response == nil {
			return "", errors.New("received nil response from chat model")
		}

		return response.Content, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	graph.AddLambdaNode("retriever", retrieverNode)
	graph.AddLambdaNode("context_builder", contextBuilder)
	graph.AddLambdaNode("chat", chatModelNode)

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á custom node ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏ß‡∏° input
	graph.AddLambdaNode("prepare_input", compose.InvokableLambda(func(ctx context.Context, query string) (map[string]interface{}, error) {
		// Retrieve documents first
		docs, err := retriever.Retrieve(ctx, query, 3)
		if err != nil {
			return nil, err
		}
		
		return map[string]interface{}{
			"query":     query,
			"documents": docs,
		}, nil
	}))

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges
	graph.AddEdge(compose.START, "prepare_input")
	graph.AddEdge("prepare_input", "context_builder")
	graph.AddEdge("context_builder", "chat")
	graph.AddEdge("chat", compose.END)

	// Compile
	runnable, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile basic RAG graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
	testQueries := []string{
		"Eino Graph ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?",
		"Goroutine ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?",
		"‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Docker",
		"‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ REST API",
	}

	for i, query := range testQueries {
		fmt.Printf("\n--- Basic RAG Test %d ---\n", i+1)
		fmt.Printf("Query: %s\n", query)
		
		testCtx, cancel := context.WithTimeout(ctx, 60*time.Second)
		result, err := runnable.Invoke(testCtx, query)
		cancel()
		
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}
		
		fmt.Printf("Response:\n%s\n", result)
		fmt.Println(strings.Repeat("-", 80))
	}

	return nil
}

// Advanced RAG with Context Filtering
func runAdvancedRAG(ctx context.Context, model *openai.ChatModel, retriever *MockRetriever) error {
	graph := compose.NewGraph[map[string]interface{}, string]()

	// Query Analyzer - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå query ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
	queryAnalyzer := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (map[string]interface{}, error) {
		originalQuery, ok := input["query"].(string)
		if !ok || strings.TrimSpace(originalQuery) == "" {
			return nil, errors.New("query is required")
		}

		language, _ := input["language"].(string)
		if language == "" {
			language = "auto" // auto-detect
		}

		userLevel, _ := input["user_level"].(string)
		if userLevel == "" {
			userLevel = "intermediate"
		}

		// Analyze query to extract keywords and intent
		queryLower := strings.ToLower(originalQuery)
		var enhancedKeywords []string
		var queryType string

		// Detect query type
		if strings.Contains(queryLower, "‡∏Ñ‡∏∑‡∏≠") || strings.Contains(queryLower, "what") || strings.Contains(queryLower, "‡∏≠‡∏∞‡πÑ‡∏£") {
			queryType = "definition"
		} else if strings.Contains(queryLower, "‡∏¢‡∏±‡∏á‡πÑ‡∏á") || strings.Contains(queryLower, "how") || strings.Contains(queryLower, "‡∏ß‡∏¥‡∏ò‡∏µ") {
			queryType = "how-to"
		} else if strings.Contains(queryLower, "‡∏ó‡∏≥‡πÑ‡∏°") || strings.Contains(queryLower, "why") || strings.Contains(queryLower, "‡πÄ‡∏û‡∏£‡∏≤‡∏∞") {
			queryType = "explanation"
		} else {
			queryType = "general"
		}

		// Extract and enhance keywords
		words := strings.Fields(originalQuery)
		for _, word := range words {
			word = strings.ToLower(strings.Trim(word, "?.,!"))
			if len(word) > 2 && !isStopWord(word) {
				enhancedKeywords = append(enhancedKeywords, word)
			}
		}

		enhancedQuery := strings.Join(enhancedKeywords, " ")

		fmt.Printf("üî¨ Query Analyzer: Type='%s', Enhanced='%s'\n", queryType, enhancedQuery)

		return map[string]interface{}{
			"original_query":    originalQuery,
			"enhanced_query":    enhancedQuery,
			"query_type":       queryType,
			"language":         language,
			"user_level":       userLevel,
			"keywords":         enhancedKeywords,
		}, nil
	})

	// Advanced Retriever - ‡πÉ‡∏ä‡πâ enhanced query ‡πÅ‡∏•‡∏∞ filtering
	advancedRetriever := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) ([]Document, error) {
		enhancedQuery, _ := input["enhanced_query"].(string)
		language, _ := input["language"].(string)
		queryType, _ := input["query_type"].(string)

		fmt.Printf("üîç Advanced Retriever: Searching with filters\n")
		
		// ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ enhanced query
		allDocs, err := retriever.Retrieve(ctx, enhancedQuery, 6) // ‡∏Ç‡∏≠‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ filter
		if err != nil {
			return nil, fmt.Errorf("retrieval failed: %w", err)
		}

		// Filter documents based on language and type
		var filteredDocs []Document
		for _, doc := range allDocs {
			// Language filtering
			if language != "auto" && language != "" {
				if docLang, exists := doc.Metadata["language"]; exists && docLang != language {
					continue
				}
			}

			// Type-based scoring (prefer certain types for certain queries)
			include := true
			switch queryType {
			case "definition":
				// Prefer documentation
				if docType, exists := doc.Metadata["type"]; exists && docType != "documentation" {
					// Still include but with lower priority
				}
			case "how-to":
				// Prefer tutorials
				if docType, exists := doc.Metadata["type"]; exists && docType != "tutorial" {
					// Still include but with lower priority
				}
			}

			if include {
				filteredDocs = append(filteredDocs, doc)
			}
		}

		// Limit to top 3
		if len(filteredDocs) > 3 {
			filteredDocs = filteredDocs[:3]
		}

		fmt.Printf("  Filtered to %d documents (from %d)\n", len(filteredDocs), len(allDocs))
		return filteredDocs, nil
	})

	// Smart Context Builder - ‡∏™‡∏£‡πâ‡∏≤‡∏á context ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° user level
	smartContextBuilder := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) ([]*schema.Message, error) {
		originalQuery, _ := input["original_query"].(string)
		docs, ok := input["documents"].([]Document)
		if !ok {
			return nil, errors.New("documents are required")
		}
		userLevel, _ := input["user_level"].(string)
		queryType, _ := input["query_type"].(string)

		// ‡∏™‡∏£‡πâ‡∏≤‡∏á context ‡∏ï‡∏≤‡∏° user level
		var contextIntro string
		switch userLevel {
		case "beginner":
			contextIntro = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:"
		case "intermediate":
			contextIntro = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:"
		case "expert":
			contextIntro = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:"
		default:
			contextIntro = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:"
		}

		var contextParts []string
		for i, doc := range docs {
			contextParts = append(contextParts, fmt.Sprintf("%d. %s", i+1, doc.Content))
		}

		context := fmt.Sprintf("%s\n%s", contextIntro, strings.Join(contextParts, "\n"))

		// ‡∏õ‡∏£‡∏±‡∏ö system prompt ‡∏ï‡∏≤‡∏° query type ‡πÅ‡∏•‡∏∞ user level
		var systemPrompt string
		switch queryType {
		case "definition":
			systemPrompt = fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢

%s

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö`, context)
		case "how-to":
			systemPrompt = fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏π‡∏™‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

%s

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢`, context)
		case "explanation":
			systemPrompt = fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏õ

%s

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏• ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå`, context)
		default:
			systemPrompt = fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤‡∏á

%s

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤`, context)
		}

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(originalQuery),
		}

		fmt.Printf("üß† Smart Context: Built %s prompt for %s level\n", queryType, userLevel)
		return messages, nil
	})

	// Data Flow Node - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ data flow ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á nodes
	dataFlowNode := compose.InvokableLambda(func(ctx context.Context, analyzed map[string]interface{}) (map[string]interface{}, error) {
		// Retrieve documents using analyzed query
		docs, err := retriever.Retrieve(ctx, analyzed["enhanced_query"].(string), 6)
		if err != nil {
			return nil, err
		}

		// Add documents to the analyzed data
		result := make(map[string]interface{})
		for k, v := range analyzed {
			result[k] = v
		}
		result["documents"] = docs

		return result, nil
	})

	// Chat Model Node
	chatModelNode := compose.InvokableLambda(func(ctx context.Context, messages []*schema.Message) (string, error) {
		fmt.Printf("ü§ñ Advanced RAG Chat: Generating contextual response\n")
		
		llamCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
		defer cancel()

		response, err := model.Generate(llamCtx, messages)
		if err != nil {
			return "", fmt.Errorf("chat model generation failed: %w", err)
		}

		if response == nil {
			return "", errors.New("received nil response from chat model")
		}

		return response.Content, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	graph.AddLambdaNode("query_analyzer", queryAnalyzer)
	graph.AddLambdaNode("data_flow", dataFlowNode)
	graph.AddLambdaNode("context_builder", smartContextBuilder)
	graph.AddLambdaNode("chat", chatModelNode)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges
	graph.AddEdge(compose.START, "query_analyzer")
	graph.AddEdge("query_analyzer", "data_flow")
	graph.AddEdge("data_flow", "context_builder")
	graph.AddEdge("context_builder", "chat")
	graph.AddEdge("chat", compose.END)

	// Compile
	runnable, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile advanced RAG graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
	testCases := []map[string]interface{}{
		{
			"query":      "Eino Graph ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?",
			"language":   "thai",
			"user_level": "beginner",
		},
		{
			"query":      "Goroutine ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?",
			"language":   "thai", 
			"user_level": "intermediate",
		},
		{
			"query":      "‡∏ó‡∏≥‡πÑ‡∏° Docker ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç?",
			"language":   "auto",
			"user_level": "expert",
		},
		{
			"query":      "How to design REST API?",
			"language":   "english",
			"user_level": "intermediate",
		},
	}

	for i, testCase := range testCases {
		fmt.Printf("\n--- Advanced RAG Test %d ---\n", i+1)
		fmt.Printf("Query: %s (Level: %s, Lang: %s)\n", testCase["query"], testCase["user_level"], testCase["language"])
		
		testCtx, cancel := context.WithTimeout(ctx, 60*time.Second)
		result, err := runnable.Invoke(testCtx, testCase)
		cancel()
		
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}
		
		fmt.Printf("Response:\n%s\n", result)
		fmt.Println(strings.Repeat("-", 80))
	}

	return nil
}

// Multi-Step RAG
func runMultiStepRAG(ctx context.Context, model *openai.ChatModel, retriever *MockRetriever) error {
	graph := compose.NewGraph[string, string]()

	// Step 1: Query Understanding
	queryUnderstanding := compose.InvokableLambda(func(ctx context.Context, query string) (map[string]interface{}, error) {
		fmt.Printf("üìù Step 1: Understanding query '%s'\n", query)
		
		// Use LLM to understand and decompose query
		messages := []*schema.Message{
			schema.SystemMessage(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° 
‡πÇ‡∏õ‡∏£‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏:
1. ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (definition, how-to, comparison, troubleshooting)
2. ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å
3. ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
4. ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô

‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON:
{
  "type": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°",
  "main_topic": "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å", 
  "search_terms": ["‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤1", "‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤2"],
  "complexity": "basic|intermediate|advanced"
}`),
			schema.UserMessage(query),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return nil, fmt.Errorf("query understanding failed: %w", err)
		}

		fmt.Printf("  Analysis: %s\n", response.Content)

		return map[string]interface{}{
			"original_query": query,
			"analysis":      response.Content,
			"step":          1,
		}, nil
	})

	// Step 2: Knowledge Retrieval
	knowledgeRetrieval := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (map[string]interface{}, error) {
		originalQuery := input["original_query"].(string)
		
		fmt.Printf("üîç Step 2: Retrieving knowledge\n")
		
		// Retrieve based on original query
		docs, err := retriever.Retrieve(ctx, originalQuery, 4)
		if err != nil {
			return nil, fmt.Errorf("knowledge retrieval failed: %w", err)
		}

		// If not enough docs, try with individual keywords
		if len(docs) < 2 {
			fmt.Printf("  Not enough docs, trying keyword search...\n")
			words := strings.Fields(strings.ToLower(originalQuery))
			for _, word := range words {
				if len(word) > 3 && !isStopWord(word) {
					moreDocs, err := retriever.Retrieve(ctx, word, 2)
					if err == nil {
						docs = append(docs, moreDocs...)
					}
				}
			}
		}

		// Remove duplicates
		uniqueDocs := make(map[string]Document)
		for _, doc := range docs {
			uniqueDocs[doc.ID] = doc
		}

		finalDocs := make([]Document, 0, len(uniqueDocs))
		for _, doc := range uniqueDocs {
			finalDocs = append(finalDocs, doc)
		}

		fmt.Printf("  Retrieved %d unique documents\n", len(finalDocs))

		result := make(map[string]interface{})
		for k, v := range input {
			result[k] = v
		}
		result["documents"] = finalDocs
		result["step"] = 2

		return result, nil
	})

	// Step 3: Context Synthesis
	contextSynthesis := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (map[string]interface{}, error) {
		docs := input["documents"].([]Document)
		originalQuery := input["original_query"].(string)
		analysis := input["analysis"].(string)
		
		fmt.Printf("üß† Step 3: Synthesizing context\n")
		
		// Use LLM to synthesize retrieved information
		var docContents []string
		for i, doc := range docs {
			docContents = append(docContents, fmt.Sprintf("Document %d: %s", i+1, doc.Content))
		}

		combinedDocs := strings.Join(docContents, "\n\n")

		messages := []*schema.Message{
			schema.SystemMessage(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°

‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£:
` + combinedDocs + `

‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
` + analysis + `

‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà:
1. ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
2. ‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°`),
			schema.UserMessage(fmt.Sprintf("‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: %s", originalQuery)),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return nil, fmt.Errorf("context synthesis failed: %w", err)
		}

		fmt.Printf("  Synthesized context (%d chars)\n", len(response.Content))

		result := make(map[string]interface{})
		for k, v := range input {
			result[k] = v
		}
		result["synthesized_context"] = response.Content
		result["step"] = 3

		return result, nil
	})

	// Step 4: Final Answer Generation
	answerGeneration := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (string, error) {
		originalQuery := input["original_query"].(string)
		synthesizedContext := input["synthesized_context"].(string)
		
		fmt.Printf("‚ú® Step 4: Generating final answer\n")
		
		messages := []*schema.Message{
			schema.SystemMessage(fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥

‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡πâ‡∏ß:
%s

‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢:
1. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
2. ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
3. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
4. ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ã‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏ï‡∏¢‡πå`, synthesizedContext)),
			schema.UserMessage(originalQuery),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("answer generation failed: %w", err)
		}

		fmt.Printf("  Generated final answer (%d chars)\n", len(response.Content))
		return response.Content, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	graph.AddLambdaNode("query_understanding", queryUnderstanding)
	graph.AddLambdaNode("knowledge_retrieval", knowledgeRetrieval)
	graph.AddLambdaNode("context_synthesis", contextSynthesis)
	graph.AddLambdaNode("answer_generation", answerGeneration)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges
	graph.AddEdge(compose.START, "query_understanding")
	graph.AddEdge("query_understanding", "knowledge_retrieval")
	graph.AddEdge("knowledge_retrieval", "context_synthesis")
	graph.AddEdge("context_synthesis", "answer_generation")
	graph.AddEdge("answer_generation", compose.END)

	// Compile
	runnable, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile multi-step RAG graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
	testQueries := []string{
		"‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Goroutine ‡∏Å‡∏±‡∏ö Thread ‡∏õ‡∏Å‡∏ï‡∏¥",
		"‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Eino Graph ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Docker",
		"‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô REST API ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç",
	}

	for i, query := range testQueries {
		fmt.Printf("\n--- Multi-Step RAG Test %d ---\n", i+1)
		fmt.Printf("Query: %s\n", query)
		
		testCtx, cancel := context.WithTimeout(ctx, 120*time.Second) // More time for multi-step
		result, err := runnable.Invoke(testCtx, query)
		cancel()
		
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}
		
		fmt.Printf("\nFinal Answer:\n%s\n", result)
		fmt.Println(strings.Repeat("=", 80))
	}

	return nil
}

// Helper function to check stop words
func isStopWord(word string) bool {
	stopWords := map[string]bool{
		"‡∏Ñ‡∏∑‡∏≠": true, "‡πÄ‡∏õ‡πá‡∏ô": true, "‡πÅ‡∏•‡∏∞": true, "‡∏´‡∏£‡∏∑‡∏≠": true, "‡∏ó‡∏µ‡πà": true,
		"‡πÉ‡∏ô": true, "‡∏Å‡∏±‡∏ö": true, "‡πÇ‡∏î‡∏¢": true, "‡πÉ‡∏´‡πâ": true, "‡πÑ‡∏î‡πâ": true,
		"‡∏°‡∏µ": true, "‡πÑ‡∏°‡πà": true, "‡πÅ‡∏•‡πâ‡∏ß": true, "‡∏à‡∏∞": true, "‡∏Å‡πá": true,
		"the": true, "is": true, "and": true, "or": true, "in": true,
		"to": true, "of": true, "for": true, "with": true, "by": true,
		"a": true, "an": true, "as": true, "at": true, "be": true,
	}
	return stopWords[word]
}