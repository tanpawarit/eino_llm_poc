package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"strings"

	"github.com/cloudwego/eino-ext/components/model/openai"
	"github.com/cloudwego/eino/compose"
	"github.com/joho/godotenv"
)

func main() {
	// Load environment
	err := godotenv.Load()
	if err != nil {
		log.Fatal("Error loading .env file")
	}

	ctx := context.Background()
	apiKey := os.Getenv("OPENROUTER_API_KEY")
	if apiKey == "" {
		fmt.Println("Please set OPENROUTER_API_KEY environment variable")
		return
	}

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á model configuration
	config := &openai.ChatModelConfig{
		APIKey:  apiKey,
		BaseURL: "https://openrouter.ai/api/v1",
		Model:   "openai/gpt-3.5-turbo",
	}

	model, err := openai.NewChatModel(ctx, config)
	if err != nil {
		fmt.Printf("Error creating model: %v\n", err)
		return
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Conditional Branching ===
	fmt.Println("=== Conditional Branching Graph ===")
	runConditionalBranching(ctx, model)

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Multi-Branch Processing ===
	fmt.Println("\n=== Multi-Branch Processing ===")
	runMultiBranchProcessing(ctx, model)
}

// Conditional Branching ‡∏î‡πâ‡∏ß‡∏¢ explicit routing
func runConditionalBranching(ctx context.Context, model *openai.ChatModel) {
	graph := compose.NewGraph[string, string]()

	// Single router that handles routing internally (avoiding merge conflicts)
	router := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		// ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå input ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î metadata
		var route, analysis, result string

		if len(input) < 15 {
			route = "short"
			analysis = "SHORT_TEXT"
			result = fmt.Sprintf("üìù Short Processed: '%s' [quick response]", input)
			fmt.Printf("üîç Analyzer: Input '%s' -> Route: %s, Analysis: %s\n", input, route, analysis)
			fmt.Printf("Short Processor: %s\n", result)
		} else if strings.Contains(strings.ToLower(input), "urgent") || strings.Contains(strings.ToLower(input), "‡∏î‡πà‡∏ß‡∏ô") {
			route = "urgent"
			analysis = "URGENT_REQUEST"
			result = fmt.Sprintf("üö® Urgent Processed: '%s' [high priority response]", input)
			fmt.Printf("üîç Analyzer: Input '%s' -> Route: %s, Analysis: %s\n", input, route, analysis)
			fmt.Printf("Urgent Processor: %s\n", result)
		} else {
			route = "normal"
			analysis = "NORMAL_TEXT"
			words := strings.Fields(input)
			result = fmt.Sprintf("üìö Normal Processed: '%s' [detailed analysis: %d words]", input, len(words))
			fmt.Printf("üîç Analyzer: Input '%s' -> Route: %s, Analysis: %s\n", input, route, analysis)
			fmt.Printf("Normal Processor: %s\n", result)
		}

		final := fmt.Sprintf("‚úÖ Final Result: %s", result)
		fmt.Printf("Aggregator: %s\n", final)
		return final, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° node ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
	graph.AddLambdaNode("router", router)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
	graph.AddEdge(compose.START, "router")
	graph.AddEdge("router", compose.END)

	// Compile ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö
	runnable, err := graph.Compile(ctx)
	if err != nil {
		fmt.Printf("Error compiling conditional graph: %v\n", err)
		return
	}

	testInputs := []string{
		"‡∏™‡∏±‡πâ‡∏ô",
		"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡πÄ‡∏£‡πá‡∏ß",
		"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°",
	}

	for i, input := range testInputs {
		fmt.Printf("\n--- Test %d ---\n", i+1)
		fmt.Printf("Input: %s\n", input)

		result, err := runnable.Invoke(ctx, input)
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}

		fmt.Printf("Result: %s\n", result)
	}
}

// Multi-branch processing ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞ branch ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
func runMultiBranchProcessing(ctx context.Context, model *openai.ChatModel) {
	graph := compose.NewGraph[string, string]()

	// Single processor that handles all cases internally (avoiding merge conflicts)
	conditionalProcessor := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		// ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á input
		var category, result string
		inputLower := strings.ToLower(input)

		if strings.Contains(inputLower, "question") || strings.Contains(inputLower, "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°") || strings.Contains(inputLower, "?") {
			category = "QUESTION"
			result = fmt.Sprintf("‚ùì Q&A Response: '%s' -> This looks like a question requiring detailed analysis", input)
			fmt.Printf("üè∑Ô∏è Classifier: '%s' -> Category: %s\n", input, category)
			fmt.Printf("Question Processor: %s\n", result)
		} else if strings.Contains(inputLower, "command") || strings.Contains(inputLower, "‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á") {
			category = "COMMAND"
			result = fmt.Sprintf("‚ö° Command Response: '%s' -> Executing command with high priority", input)
			fmt.Printf("üè∑Ô∏è Classifier: '%s' -> Category: %s\n", input, category)
			fmt.Printf("Command Processor: %s\n", result)
		} else if len(input) < 10 {
			category = "SIMPLE"
			result = fmt.Sprintf("‚ö° Simple Response: '%s' -> Quick processing completed", input)
			fmt.Printf("üè∑Ô∏è Classifier: '%s' -> Category: %s\n", input, category)
			fmt.Printf("Simple Processor: %s\n", result)
		} else {
			category = "COMPLEX"
			words := strings.Fields(input)
			chars := len(input)
			result = fmt.Sprintf("üî¨ Complex Response: '%s' -> Advanced analysis [%d words, %d chars]", input, len(words), chars)
			fmt.Printf("üè∑Ô∏è Classifier: '%s' -> Category: %s\n", input, category)
			fmt.Printf("Complex Processor: %s\n", result)
		}

		return result, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° node ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
	graph.AddLambdaNode("conditional_proc", conditionalProcessor)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
	graph.AddEdge(compose.START, "conditional_proc")
	graph.AddEdge("conditional_proc", compose.END)

	// Compile ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö
	runnable, err := graph.Compile(ctx)
	if err != nil {
		fmt.Printf("Error compiling multi-branch graph: %v\n", err)
		return
	}

	testInputs := []string{
		"Hello?",
		"‡∏™‡∏±‡πâ‡∏ô",
		"Execute command now",
		"‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö",
		"What is the weather today?",
	}

	for i, input := range testInputs {
		fmt.Printf("\n--- Test %d ---\n", i+1)
		fmt.Printf("Input: %s\n", input)

		result, err := runnable.Invoke(ctx, input)
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}

		fmt.Printf("Result: %s\n", result)
	}
}
