package main

import (
	"context"
	"errors"
	"fmt"
	"log"
	"os"
	"strings"
	"time"

	"github.com/cloudwego/eino-ext/components/model/openai"
	"github.com/cloudwego/eino/compose"
	"github.com/cloudwego/eino/schema"
	"github.com/joho/godotenv"
)

// UserRequest represents a user's request with metadata
type UserRequest struct {
	Message    string            `json:"message"`
	UserType   string            `json:"user_type"`   // beginner, intermediate, expert
	Topic      string            `json:"topic"`       // programming, math, general
	Language   string            `json:"language"`    // thai, english
	Priority   string            `json:"priority"`    // low, normal, high, urgent
	Metadata   map[string]string `json:"metadata"`
}

// RoutingDecision represents routing logic output
type RoutingDecision struct {
	NextNode   string            `json:"next_node"`
	Confidence float64           `json:"confidence"`
	Reasoning  string            `json:"reasoning"`
	Metadata   map[string]string `json:"metadata"`
}

// CollectedResult represents aggregated results from multiple nodes
type CollectedResult struct {
	Results    []string          `json:"results"`
	Sources    []string          `json:"sources"`
	Confidence float64           `json:"confidence"`
	Summary    string            `json:"summary"`
	Metadata   map[string]string `json:"metadata"`
}

// main function for routing and edge examples
func main() {
	if err := runRoutingEdgeExamples(); err != nil {
		log.Fatalf("Error running routing edge examples: %v", err)
	}
}

// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Router, Collector, ‡πÅ‡∏•‡∏∞ Broadcaster Nodes ‡∏û‡∏£‡πâ‡∏≠‡∏° Advanced Edges
func runRoutingEdgeExamples() error {
	// Load environment
	if err := godotenv.Load(); err != nil {
		log.Printf("Warning: .env file not found or couldn't be loaded: %v", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	apiKey := os.Getenv("OPENROUTER_API_KEY")
	if apiKey == "" {
		return errors.New("OPENROUTER_API_KEY environment variable is required")
	}

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á Chat Model
	config := &openai.ChatModelConfig{
		APIKey:  apiKey,
		BaseURL: "https://openrouter.ai/api/v1",
		Model:   "openai/gpt-3.5-turbo",
	}

	model, err := openai.NewChatModel(ctx, config)
	if err != nil {
		return fmt.Errorf("failed to create chat model: %w", err)
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1: Router Node with Conditional Edges ===
	fmt.Println("=== Router Node with Conditional Edges ===")
	if err := runConditionalRouterExample(ctx, model); err != nil {
		return fmt.Errorf("conditional router example failed: %w", err)
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2: Collector Node (Fan-in Pattern) ===
	fmt.Println("\n=== Collector Node (Fan-in Pattern) ===")
	if err := runCollectorExample(ctx, model); err != nil {
		return fmt.Errorf("collector example failed: %w", err)
	}

	// === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3: Broadcaster Node (Fan-out Pattern) ===
	fmt.Println("\n=== Broadcaster Node (Fan-out Pattern) ===")
	if err := runBroadcasterExample(ctx, model); err != nil {
		return fmt.Errorf("broadcaster example failed: %w", err)
	}

	return nil
}

// Router Node with Conditional Edges
func runConditionalRouterExample(ctx context.Context, model *openai.ChatModel) error {
	graph := compose.NewGraph[UserRequest, string]()

	// Request Analyzer - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
	requestAnalyzer := compose.InvokableLambda(func(ctx context.Context, request UserRequest) (RoutingDecision, error) {
		fmt.Printf("üîç Request Analyzer: Analyzing request from %s user\n", request.UserType)
		fmt.Printf("  Message: %s\n", request.Message)
		fmt.Printf("  Topic: %s, Language: %s, Priority: %s\n", request.Topic, request.Language, request.Priority)

		// Smart routing logic
		var nextNode string
		var confidence float64
		var reasoning string

		messageLower := strings.ToLower(request.Message)

		// Topic-based routing
		switch request.Topic {
		case "programming":
			if strings.Contains(messageLower, "bug") || strings.Contains(messageLower, "error") || strings.Contains(messageLower, "debug") {
				nextNode = "debug_specialist"
				confidence = 0.9
				reasoning = "Detected debugging/error-related programming question"
			} else if strings.Contains(messageLower, "performance") || strings.Contains(messageLower, "optimize") {
				nextNode = "performance_specialist"
				confidence = 0.85
				reasoning = "Detected performance optimization question"
			} else {
				nextNode = "programming_assistant"
				confidence = 0.8
				reasoning = "General programming question"
			}
		case "math":
			if strings.Contains(messageLower, "calculate") || strings.Contains(messageLower, "‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì") {
				nextNode = "math_calculator"
				confidence = 0.95
				reasoning = "Detected calculation request"
			} else {
				nextNode = "math_tutor"
				confidence = 0.8
				reasoning = "Math learning/explanation request"
			}
		default:
			// Priority-based routing for general topics
			switch request.Priority {
			case "urgent":
				nextNode = "priority_handler"
				confidence = 0.9
				reasoning = "High priority request needs immediate attention"
			case "high":
				nextNode = "senior_assistant"
				confidence = 0.8
				reasoning = "High priority request"
			default:
				nextNode = "general_assistant"
				confidence = 0.7
				reasoning = "Standard general request"
			}
		}

		// User level adjustment
		if request.UserType == "beginner" && (nextNode == "debug_specialist" || nextNode == "performance_specialist") {
			nextNode = "beginner_programming_helper"
			reasoning = "Adjusted for beginner level user"
		}

		decision := RoutingDecision{
			NextNode:   nextNode,
			Confidence: confidence,
			Reasoning:  reasoning,
			Metadata: map[string]string{
				"user_type": request.UserType,
				"topic":     request.Topic,
				"priority":  request.Priority,
			},
		}

		fmt.Printf("üéØ Routing Decision: %s (confidence: %.2f)\n", nextNode, confidence)
		fmt.Printf("  Reasoning: %s\n", reasoning)

		return decision, nil
	})

	// Different specialist nodes
	debugSpecialist := compose.InvokableLambda(func(ctx context.Context, request UserRequest) (string, error) {
		fmt.Printf("üêõ Debug Specialist: Handling debug request\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô debugging ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÇ‡∏Ñ‡πâ‡∏î
‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(request.Message),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("debug specialist generation failed: %w", err)
		}

		return fmt.Sprintf("üêõ Debug Specialist Analysis:\n%s", response.Content), nil
	})

	performanceSpecialist := compose.InvokableLambda(func(ctx context.Context, request UserRequest) (string, error) {
		fmt.Printf("‚ö° Performance Specialist: Handling optimization request\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô performance optimization
‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ß‡∏±‡∏î‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(request.Message),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("performance specialist generation failed: %w", err)
		}

		return fmt.Sprintf("‚ö° Performance Specialist Analysis:\n%s", response.Content), nil
	})

	mathCalculator := compose.InvokableLambda(func(ctx context.Context, request UserRequest) (string, error) {
		fmt.Printf("üßÆ Math Calculator: Processing calculation\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(request.Message),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("math calculator generation failed: %w", err)
		}

		return fmt.Sprintf("üßÆ Math Calculator Result:\n%s", response.Content), nil
	})

	generalAssistant := compose.InvokableLambda(func(ctx context.Context, request UserRequest) (string, error) {
		fmt.Printf("ü§ñ General Assistant: Handling general request\n")
		
		var systemPrompt string
		switch request.UserType {
		case "beginner":
			systemPrompt = "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà"
		case "expert":
			systemPrompt = "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç"
		default:
			systemPrompt = "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå"
		}

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(request.Message),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("general assistant generation failed: %w", err)
		}

		return fmt.Sprintf("ü§ñ General Assistant Response:\n%s", response.Content), nil
	})

	// Router Logic Node - ‡πÉ‡∏ä‡πâ routing decision ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠
	routerLogic := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (string, error) {
		request, ok := input["request"].(UserRequest)
		if !ok {
			return "", errors.New("request not found in input")
		}

		decision, ok := input["decision"].(RoutingDecision)
		if !ok {
			return "", errors.New("routing decision not found in input")
		}

		fmt.Printf("üö¶ Router Logic: Routing to %s\n", decision.NextNode)

		// Execute appropriate specialist
		switch decision.NextNode {
		case "debug_specialist":
			return debugSpecialist.Invoke(ctx, request)
		case "performance_specialist":
			return performanceSpecialist.Invoke(ctx, request)
		case "math_calculator":
			return mathCalculator.Invoke(ctx, request)
		default:
			return generalAssistant.Invoke(ctx, request)
		}
	})

	// Combiner node to prepare data for router
	combiner := compose.InvokableLambda(func(ctx context.Context, request UserRequest) (map[string]interface{}, error) {
		// Analyze request first
		decision, err := requestAnalyzer.Invoke(ctx, request)
		if err != nil {
			return nil, err
		}

		return map[string]interface{}{
			"request":  request,
			"decision": decision,
		}, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	graph.AddLambdaNode("combiner", combiner)
	graph.AddLambdaNode("router_logic", routerLogic)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges
	graph.AddEdge(compose.START, "combiner")
	graph.AddEdge("combiner", "router_logic")
	graph.AddEdge("router_logic", compose.END)

	// Compile
	runnable, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile conditional router graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö conditional routing
	testRequests := []UserRequest{
		{
			Message:  "My Go application has a memory leak, how do I debug it?",
			UserType: "intermediate",
			Topic:    "programming",
			Language: "english",
			Priority: "high",
		},
		{
			Message:  "How to optimize database queries?",
			UserType: "expert",
			Topic:    "programming",
			Language: "english",
			Priority: "normal",
		},
		{
			Message:  "Calculate 15 * 25 + 100",
			UserType: "beginner",
			Topic:    "math",
			Language: "english",
			Priority: "normal",
		},
		{
			Message:  "What is machine learning?",
			UserType: "beginner",
			Topic:    "general",
			Language: "english",
			Priority: "low",
		},
		{
			Message:  "URGENT: Production server is down!",
			UserType: "expert",
			Topic:    "general",
			Language: "english",
			Priority: "urgent",
		},
	}

	for i, request := range testRequests {
		fmt.Printf("\n--- Conditional Router Test %d ---\n", i+1)
		fmt.Printf("Request: %+v\n", request)
		
		testCtx, cancel := context.WithTimeout(ctx, 60*time.Second)
		result, err := runnable.Invoke(testCtx, request)
		cancel()
		
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}
		
		fmt.Printf("Response:\n%s\n", result)
		fmt.Println(strings.Repeat("-", 80))
	}

	return nil
}

// Collector Node (Fan-in Pattern)
func runCollectorExample(ctx context.Context, model *openai.ChatModel) error {
	graph := compose.NewGraph[string, string]()

	// Question Broadcaster - ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏õ‡∏´‡∏•‡∏≤‡∏¢ specialists
	questionBroadcaster := compose.InvokableLambda(func(ctx context.Context, question string) (map[string]string, error) {
		fmt.Printf("üì° Question Broadcaster: Broadcasting question to specialists\n")
		fmt.Printf("  Question: %s\n", question)

		// Broadcast to multiple specialists
		return map[string]string{
			"technical":    question,
			"practical":    question,
			"theoretical":  question,
		}, nil
	})

	// Technical Specialist
	technicalSpecialist := compose.InvokableLambda(func(ctx context.Context, question string) (string, error) {
		fmt.Printf("üîß Technical Specialist: Analyzing technical aspects\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ ‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô implementation ‡πÅ‡∏•‡∏∞ best practices`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(question),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("technical specialist generation failed: %w", err)
		}

		return fmt.Sprintf("Technical Analysis: %s", response.Content), nil
	})

	// Practical Specialist
	practicalSpecialist := compose.InvokableLambda(func(ctx context.Context, question string) (string, error) {
		fmt.Printf("üíº Practical Specialist: Focusing on real-world application\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á ‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(question),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("practical specialist generation failed: %w", err)
		}

		return fmt.Sprintf("Practical Perspective: %s", response.Content), nil
	})

	// Theoretical Specialist
	theoreticalSpecialist := compose.InvokableLambda(func(ctx context.Context, question string) (string, error) {
		fmt.Printf("üìö Theoretical Specialist: Explaining concepts and theory\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏ó‡∏§‡∏©‡∏é‡∏µ ‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£ ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î ‡πÅ‡∏•‡∏∞‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(question),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("theoretical specialist generation failed: %w", err)
		}

		return fmt.Sprintf("Theoretical Foundation: %s", response.Content), nil
	})

	// Result Collector - ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å specialists
	resultCollector := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (CollectedResult, error) {
		fmt.Printf("üóÇÔ∏è Result Collector: Aggregating specialist responses\n")
		
		// Extract results from different specialists
		question, _ := input["question"].(string)
		
		// Collect all results
		var allResults []string
		var sources []string

		// Get results from each specialist
		if tech, err := technicalSpecialist.Invoke(ctx, question); err == nil {
			allResults = append(allResults, tech)
			sources = append(sources, "Technical Specialist")
		}

		if practical, err := practicalSpecialist.Invoke(ctx, question); err == nil {
			allResults = append(allResults, practical)
			sources = append(sources, "Practical Specialist")
		}

		if theoretical, err := theoreticalSpecialist.Invoke(ctx, question); err == nil {
			allResults = append(allResults, theoretical)
			sources = append(sources, "Theoretical Specialist")
		}

		// Calculate confidence based on consensus
		confidence := 0.8 // Base confidence
		if len(allResults) >= 3 {
			confidence = 0.95 // High confidence with multiple perspectives
		}

		collected := CollectedResult{
			Results:    allResults,
			Sources:    sources,
			Confidence: confidence,
			Summary:    fmt.Sprintf("Collected %d perspectives on: %s", len(allResults), question),
			Metadata: map[string]string{
				"collection_method": "parallel_specialists",
				"num_sources":       fmt.Sprintf("%d", len(sources)),
			},
		}

		fmt.Printf("  Collected %d results from %d sources\n", len(allResults), len(sources))
		return collected, nil
	})

	// Final Synthesizer - ‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
	finalSynthesizer := compose.InvokableLambda(func(ctx context.Context, collected CollectedResult) (string, error) {
		fmt.Printf("üß† Final Synthesizer: Creating comprehensive response\n")
		
		// Combine all perspectives into comprehensive answer
		combinedInput := fmt.Sprintf("Question: %s\n\nPerspectives from specialists:\n", collected.Summary)
		for i, result := range collected.Results {
			combinedInput += fmt.Sprintf("\n%s:\n%s\n", collected.Sources[i], result)
		}

		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á
‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡∏™‡∏°‡∏î‡∏∏‡∏•
‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ ‡πÅ‡∏•‡∏∞‡∏ó‡∏§‡∏©‡∏é‡∏µ`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(combinedInput),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("final synthesizer generation failed: %w", err)
		}

		return fmt.Sprintf("üéØ Comprehensive Answer (Confidence: %.2f):\n%s\n\nSources: %s", 
			collected.Confidence, response.Content, strings.Join(collected.Sources, ", ")), nil
	})

	// Data flow nodes
	dataFlow1 := compose.InvokableLambda(func(ctx context.Context, question string) (map[string]interface{}, error) {
		collected, err := resultCollector.Invoke(ctx, map[string]interface{}{"question": question})
		if err != nil {
			return nil, err
		}
		return map[string]interface{}{"collected": collected}, nil
	})

	extractCollected := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (CollectedResult, error) {
		collected, ok := input["collected"].(CollectedResult)
		if !ok {
			return CollectedResult{}, errors.New("collected result not found")
		}
		return collected, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	graph.AddLambdaNode("data_flow", dataFlow1)
	graph.AddLambdaNode("extract_collected", extractCollected)
	graph.AddLambdaNode("final_synthesizer", finalSynthesizer)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges
	graph.AddEdge(compose.START, "data_flow")
	graph.AddEdge("data_flow", "extract_collected")
	graph.AddEdge("extract_collected", "final_synthesizer")
	graph.AddEdge("final_synthesizer", compose.END)

	// Compile
	runnable, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile collector graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö collector pattern
	testQuestions := []string{
		"Explain Go channels and goroutines",
		"How does Docker containerization work?",
		"What are the principles of REST API design?",
	}

	for i, question := range testQuestions {
		fmt.Printf("\n--- Collector Test %d ---\n", i+1)
		fmt.Printf("Question: %s\n", question)
		
		testCtx, cancel := context.WithTimeout(ctx, 120*time.Second)
		result, err := runnable.Invoke(testCtx, question)
		cancel()
		
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}
		
		fmt.Printf("Result:\n%s\n", result)
		fmt.Println(strings.Repeat("=", 80))
	}

	return nil
}

// Broadcaster Node (Fan-out Pattern)
func runBroadcasterExample(ctx context.Context, model *openai.ChatModel) error {
	graph := compose.NewGraph[string, string]()

	// Content Broadcaster - ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏´‡∏•‡∏≤‡∏¢ processors ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
	contentBroadcaster := compose.InvokableLambda(func(ctx context.Context, content string) (map[string]interface{}, error) {
		fmt.Printf("üì° Content Broadcaster: Broadcasting to multiple processors\n")
		fmt.Printf("  Content length: %d characters\n", len(content))

		// Broadcast to different processors simultaneously
		return map[string]interface{}{
			"content":           content,
			"summary_request":   content,
			"translate_request": content,
			"analyze_request":   content,
		}, nil
	})

	// Summary Processor
	summaryProcessor := compose.InvokableLambda(func(ctx context.Context, content string) (string, error) {
		fmt.Printf("üìù Summary Processor: Creating summary\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(fmt.Sprintf("‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏µ‡πâ: %s", content)),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("summary processor generation failed: %w", err)
		}

		return fmt.Sprintf("üìù Summary: %s", response.Content), nil
	})

	// Translation Processor
	translationProcessor := compose.InvokableLambda(func(ctx context.Context, content string) (string, error) {
		fmt.Printf("üåê Translation Processor: Translating content\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(fmt.Sprintf("‡πÅ‡∏õ‡∏•‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©: %s", content)),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("translation processor generation failed: %w", err)
		}

		return fmt.Sprintf("üåê Translation: %s", response.Content), nil
	})

	// Analysis Processor
	analysisProcessor := compose.InvokableLambda(func(ctx context.Context, content string) (string, error) {
		fmt.Printf("üîç Analysis Processor: Analyzing content\n")
		
		systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏ó‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÅ‡∏•‡∏∞‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤`

		messages := []*schema.Message{
			schema.SystemMessage(systemPrompt),
			schema.UserMessage(fmt.Sprintf("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏µ‡πâ: %s", content)),
		}

		response, err := model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("analysis processor generation failed: %w", err)
		}

		return fmt.Sprintf("üîç Analysis: %s", response.Content), nil
	})

	// Result Aggregator - ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å processors
	resultAggregator := compose.InvokableLambda(func(ctx context.Context, input map[string]interface{}) (string, error) {
		fmt.Printf("üóÇÔ∏è Result Aggregator: Collecting all processor results\n")
		
		content, _ := input["content"].(string)
		
		// Process content with all processors in parallel
		var results []string
		
		// Get summary
		if summary, err := summaryProcessor.Invoke(ctx, content); err == nil {
			results = append(results, summary)
		} else {
			results = append(results, fmt.Sprintf("üìù Summary: Error - %v", err))
		}

		// Get translation
		if translation, err := translationProcessor.Invoke(ctx, content); err == nil {
			results = append(results, translation)
		} else {
			results = append(results, fmt.Sprintf("üåê Translation: Error - %v", err))
		}

		// Get analysis
		if analysis, err := analysisProcessor.Invoke(ctx, content); err == nil {
			results = append(results, analysis)
		} else {
			results = append(results, fmt.Sprintf("üîç Analysis: Error - %v", err))
		}

		// Combine all results
		finalResult := fmt.Sprintf("üì° Broadcast Processing Results:\n\nOriginal Content: %s\n\n%s", 
			content, strings.Join(results, "\n\n"))

		fmt.Printf("  Aggregated %d processor results\n", len(results))
		return finalResult, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	graph.AddLambdaNode("content_broadcaster", contentBroadcaster)
	graph.AddLambdaNode("result_aggregator", resultAggregator)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges
	graph.AddEdge(compose.START, "content_broadcaster")
	graph.AddEdge("content_broadcaster", "result_aggregator")
	graph.AddEdge("result_aggregator", compose.END)

	// Compile
	runnable, err := graph.Compile(ctx)
	if err != nil {
		return fmt.Errorf("failed to compile broadcaster graph: %w", err)
	}

	// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö broadcaster pattern
	testContents := []string{
		"Go ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏°‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ Google ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö concurrency ‡πÑ‡∏î‡πâ‡∏î‡∏µ",
		"Machine learning is a subset of artificial intelligence that enables computers to learn without being explicitly programmed.",
		"Docker ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏û‡πá‡∏Ñ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡πÅ‡∏•‡∏∞ dependencies ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô container ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÜ",
	}

	for i, content := range testContents {
		fmt.Printf("\n--- Broadcaster Test %d ---\n", i+1)
		fmt.Printf("Content: %s\n", content)
		
		testCtx, cancel := context.WithTimeout(ctx, 120*time.Second)
		result, err := runnable.Invoke(testCtx, content)
		cancel()
		
		if err != nil {
			fmt.Printf("Error: %v\n", err)
			continue
		}
		
		fmt.Printf("Result:\n%s\n", result)
		fmt.Println(strings.Repeat("=", 80))
	}

	return nil
}