package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"strings"
	"sync"
	"time"

	"github.com/cloudwego/eino-ext/components/model/openai"
	"github.com/cloudwego/eino/compose"
	"github.com/cloudwego/eino/schema"
	"github.com/joho/godotenv"
)

// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ö‡∏ó‡∏ó‡∏µ‡πà 9: Advanced Graph Patterns
// ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Graph ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡πÉ‡∏ô Eino

// GraphPattern - ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á graph pattern
type GraphPattern string

const (
	PatternPipeline    GraphPattern = "pipeline"
	PatternFanOut      GraphPattern = "fan_out"
	PatternFanIn       GraphPattern = "fan_in"
	PatternScatterGather GraphPattern = "scatter_gather"
	PatternMapReduce   GraphPattern = "map_reduce"
	PatternWorkflow    GraphPattern = "workflow"
	PatternDynamic     GraphPattern = "dynamic"
)

// TaskResult - ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å task
type TaskResult struct {
	NodeName  string                 `json:"node_name"`
	Input     string                 `json:"input"`
	Output    string                 `json:"output"`
	Metadata  map[string]interface{} `json:"metadata"`
	Duration  time.Duration          `json:"duration"`
	Success   bool                   `json:"success"`
	Error     string                 `json:"error,omitempty"`
}

// WorkflowContext - context ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö workflow
type WorkflowContext struct {
	WorkflowID  string                 `json:"workflow_id"`
	StartTime   time.Time              `json:"start_time"`
	Results     map[string]TaskResult  `json:"results"`
	Metadata    map[string]interface{} `json:"metadata"`
	CurrentStep string                 `json:"current_step"`
	Status      string                 `json:"status"`
	mu          sync.RWMutex
}

func NewWorkflowContext(workflowID string) *WorkflowContext {
	return &WorkflowContext{
		WorkflowID: workflowID,
		StartTime:  time.Now(),
		Results:    make(map[string]TaskResult),
		Metadata:   make(map[string]interface{}),
		Status:     "running",
	}
}

func (wc *WorkflowContext) AddResult(nodeName string, result TaskResult) {
	wc.mu.Lock()
	defer wc.mu.Unlock()
	wc.Results[nodeName] = result
}

func (wc *WorkflowContext) GetResult(nodeName string) (TaskResult, bool) {
	wc.mu.RLock()
	defer wc.mu.RUnlock()
	result, exists := wc.Results[nodeName]
	return result, exists
}

func (wc *WorkflowContext) SetCurrentStep(step string) {
	wc.mu.Lock()
	defer wc.mu.Unlock()
	wc.CurrentStep = step
}

func (wc *WorkflowContext) SetStatus(status string) {
	wc.mu.Lock()
	defer wc.mu.Unlock()
	wc.Status = status
}

// 1. Fan-Out/Fan-In Pattern
type FanOutFanInGraph struct {
	graph   *compose.Graph[string, string]
	model   *openai.ChatModel
	ctx     context.Context
	wfCtx   *WorkflowContext
}

func NewFanOutFanInGraph(model *openai.ChatModel, ctx context.Context) *FanOutFanInGraph {
	return &FanOutFanInGraph{
		graph: compose.NewGraph[string, string](),
		model: model,
		ctx:   ctx,
		wfCtx: NewWorkflowContext("fanout_fanin_001"),
	}
}

func (fofig *FanOutFanInGraph) BuildFanOutFanInGraph() {
	// Node 1: Splitter - ‡πÅ‡∏¢‡∏Å‡∏á‡∏≤‡∏ô‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏™‡πà‡∏ß‡∏ô
	splitter := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		fofig.wfCtx.SetCurrentStep("splitter")
		
		fmt.Printf("üìã [Splitter] Splitting input into multiple tasks\n")
		
		// ‡πÅ‡∏¢‡∏Å input ‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏™‡πà‡∏ß‡∏ô ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö parallel
		tasks := []string{
			fmt.Sprintf("summarize: %s", input),
			fmt.Sprintf("analyze_sentiment: %s", input),
			fmt.Sprintf("extract_keywords: %s", input),
		}
		
		result := strings.Join(tasks, "|")
		
		taskResult := TaskResult{
			NodeName: "splitter",
			Input:    input,
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
			Metadata: map[string]interface{}{
				"task_count": len(tasks),
			},
		}
		fofig.wfCtx.AddResult("splitter", taskResult)
		
		return result, nil
	})

	// Node 2a: Summarizer
	summarizer := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		fofig.wfCtx.SetCurrentStep("summarizer")
		
		tasks := strings.Split(input, "|")
		var summarizeTask string
		for _, task := range tasks {
			if strings.HasPrefix(task, "summarize:") {
				summarizeTask = strings.TrimPrefix(task, "summarize: ")
				break
			}
		}
		
		fmt.Printf("üìù [Summarizer] Processing: %s\n", summarizeTask[:min(50, len(summarizeTask))]+"...")
		
		messages := []*schema.Message{
			schema.SystemMessage("‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"),
			schema.UserMessage(summarizeTask),
		}
		
		response, err := fofig.model.Generate(ctx, messages)
		if err != nil {
			return "", err
		}
		
		result := fmt.Sprintf("Summary: %s", response.Content)
		
		taskResult := TaskResult{
			NodeName: "summarizer",
			Input:    summarizeTask,
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
		}
		fofig.wfCtx.AddResult("summarizer", taskResult)
		
		return result, nil
	})

	// Node 2b: Sentiment Analyzer
	sentimentAnalyzer := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		fofig.wfCtx.SetCurrentStep("sentiment_analyzer")
		
		tasks := strings.Split(input, "|")
		var sentimentTask string
		for _, task := range tasks {
			if strings.HasPrefix(task, "analyze_sentiment:") {
				sentimentTask = strings.TrimPrefix(task, "analyze_sentiment: ")
				break
			}
		}
		
		fmt.Printf("üòä [SentimentAnalyzer] Processing: %s\n", sentimentTask[:min(50, len(sentimentTask))]+"...")
		
		messages := []*schema.Message{
			schema.SystemMessage("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (positive/negative/neutral) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•"),
			schema.UserMessage(sentimentTask),
		}
		
		response, err := fofig.model.Generate(ctx, messages)
		if err != nil {
			return "", err
		}
		
		result := fmt.Sprintf("Sentiment: %s", response.Content)
		
		taskResult := TaskResult{
			NodeName: "sentiment_analyzer",
			Input:    sentimentTask,
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
		}
		fofig.wfCtx.AddResult("sentiment_analyzer", taskResult)
		
		return result, nil
	})

	// Node 2c: Keyword Extractor
	keywordExtractor := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		fofig.wfCtx.SetCurrentStep("keyword_extractor")
		
		tasks := strings.Split(input, "|")
		var keywordTask string
		for _, task := range tasks {
			if strings.HasPrefix(task, "extract_keywords:") {
				keywordTask = strings.TrimPrefix(task, "extract_keywords: ")
				break
			}
		}
		
		fmt.Printf("üîë [KeywordExtractor] Processing: %s\n", keywordTask[:min(50, len(keywordTask))]+"...")
		
		messages := []*schema.Message{
			schema.SystemMessage("‡∏™‡∏Å‡∏±‡∏î‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÉ‡∏´‡πâ 5-10 ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"),
			schema.UserMessage(keywordTask),
		}
		
		response, err := fofig.model.Generate(ctx, messages)
		if err != nil {
			return "", err
		}
		
		result := fmt.Sprintf("Keywords: %s", response.Content)
		
		taskResult := TaskResult{
			NodeName: "keyword_extractor",
			Input:    keywordTask,
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
		}
		fofig.wfCtx.AddResult("keyword_extractor", taskResult)
		
		return result, nil
	})

	// Node 3: Aggregator - ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
	aggregator := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Time{}
		fofig.wfCtx.SetCurrentStep("aggregator")
		
		fmt.Printf("üìä [Aggregator] Combining results from parallel processors\n")
		
		// ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å parallel nodes
		// ‡πÉ‡∏ô implementation ‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å parallel node ‡πÄ‡∏™‡∏£‡πá‡∏à
		// ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å context
		
		summaryResult, _ := fofig.wfCtx.GetResult("summarizer")
		sentimentResult, _ := fofig.wfCtx.GetResult("sentiment_analyzer")
		keywordResult, _ := fofig.wfCtx.GetResult("keyword_extractor")
		
		combinedResult := fmt.Sprintf(`üîç Text Analysis Report:

%s

%s

%s

üìà Processing Summary:
- Total processing time: %v
- All tasks completed successfully`,
			summaryResult.Output,
			sentimentResult.Output,
			keywordResult.Output,
			time.Since(fofig.wfCtx.StartTime))
		
		taskResult := TaskResult{
			NodeName: "aggregator",
			Input:    input,
			Output:   combinedResult,
			Duration: time.Since(startTime),
			Success:  true,
			Metadata: map[string]interface{}{
				"components_count": 3,
			},
		}
		fofig.wfCtx.AddResult("aggregator", taskResult)
		fofig.wfCtx.SetStatus("completed")
		
		return combinedResult, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	fofig.graph.AddLambdaNode("splitter", splitter)
	fofig.graph.AddLambdaNode("summarizer", summarizer)
	fofig.graph.AddLambdaNode("sentiment_analyzer", sentimentAnalyzer)
	fofig.graph.AddLambdaNode("keyword_extractor", keywordExtractor)
	fofig.graph.AddLambdaNode("aggregator", aggregator)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges - fan-out pattern
	fofig.graph.AddEdge(compose.START, "splitter")
	
	// Fan-out: splitter ‡πÑ‡∏õ‡∏¢‡∏±‡∏á parallel processors
	fofig.graph.AddEdge("splitter", "summarizer")
	fofig.graph.AddEdge("splitter", "sentiment_analyzer")
	fofig.graph.AddEdge("splitter", "keyword_extractor")
	
	// Fan-in: parallel processors ‡∏°‡∏≤‡∏ó‡∏µ‡πà aggregator
	fofig.graph.AddEdge("summarizer", "aggregator")
	fofig.graph.AddEdge("sentiment_analyzer", "aggregator")
	fofig.graph.AddEdge("keyword_extractor", "aggregator")
	
	fofig.graph.AddEdge("aggregator", compose.END)
}

func (fofig *FanOutFanInGraph) Execute(input string) (string, error) {
	runnable, err := fofig.graph.Compile(fofig.ctx)
	if err != nil {
		return "", fmt.Errorf("failed to compile fan-out/fan-in graph: %w", err)
	}
	
	return runnable.Invoke(fofig.ctx, input)
}

func (fofig *FanOutFanInGraph) GetWorkflowContext() *WorkflowContext {
	return fofig.wfCtx
}

// 2. Map-Reduce Pattern
type MapReduceGraph struct {
	graph *compose.Graph[[]string, string]
	model *openai.ChatModel
	ctx   context.Context
	wfCtx *WorkflowContext
}

func NewMapReduceGraph(model *openai.ChatModel, ctx context.Context) *MapReduceGraph {
	return &MapReduceGraph{
		graph: compose.NewGraph[[]string, string](),
		model: model,
		ctx:   ctx,
		wfCtx: NewWorkflowContext("mapreduce_001"),
	}
}

func (mrg *MapReduceGraph) BuildMapReduceGraph() {
	// Map Phase: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞ item ‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô
	mapper := compose.InvokableLambda(func(ctx context.Context, inputs []string) (string, error) {
		startTime := time.Now()
		mrg.wfCtx.SetCurrentStep("mapper")
		
		fmt.Printf("üó∫Ô∏è [Mapper] Processing %d items\n", len(inputs))
		
		var mappedResults []string
		
		for i, input := range inputs {
			fmt.Printf("üìù [Mapper] Processing item %d: %s\n", i+1, input[:min(30, len(input))]+"...")
			
			messages := []*schema.Message{
				schema.SystemMessage("‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 100 ‡∏Ñ‡∏≥"),
				schema.UserMessage(input),
			}
			
			response, err := mrg.model.Generate(ctx, messages)
			if err != nil {
				return "", fmt.Errorf("map error for item %d: %w", i, err)
			}
			
			mappedResults = append(mappedResults, response.Content)
		}
		
		result := strings.Join(mappedResults, "|||")
		
		taskResult := TaskResult{
			NodeName: "mapper",
			Input:    strings.Join(inputs, "; "),
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
			Metadata: map[string]interface{}{
				"items_processed": len(inputs),
			},
		}
		mrg.wfCtx.AddResult("mapper", taskResult)
		
		return result, nil
	})

	// Reduce Phase: ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
	reducer := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		mrg.wfCtx.SetCurrentStep("reducer")
		
		mappedResults := strings.Split(input, "|||")
		fmt.Printf("üîÑ [Reducer] Combining %d mapped results\n", len(mappedResults))
		
		// ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô summary ‡πÉ‡∏´‡∏ç‡πà
		combinedInput := strings.Join(mappedResults, "\n\n")
		
		messages := []*schema.Message{
			schema.SystemMessage("‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"),
			schema.UserMessage(fmt.Sprintf("‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:\n\n%s", combinedInput)),
		}
		
		response, err := mrg.model.Generate(ctx, messages)
		if err != nil {
			return "", fmt.Errorf("reduce error: %w", err)
		}
		
		finalResult := fmt.Sprintf(`üìÑ Map-Reduce Summary Report:

%s

üìä Processing Details:
- Items processed: %d
- Processing time: %v
- Pattern: Map-Reduce`,
			response.Content,
			len(mappedResults),
			time.Since(mrg.wfCtx.StartTime))
		
		taskResult := TaskResult{
			NodeName: "reducer",
			Input:    input,
			Output:   finalResult,
			Duration: time.Since(startTime),
			Success:  true,
			Metadata: map[string]interface{}{
				"results_combined": len(mappedResults),
			},
		}
		mrg.wfCtx.AddResult("reducer", taskResult)
		mrg.wfCtx.SetStatus("completed")
		
		return finalResult, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	mrg.graph.AddLambdaNode("mapper", mapper)
	mrg.graph.AddLambdaNode("reducer", reducer)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges
	mrg.graph.AddEdge(compose.START, "mapper")
	mrg.graph.AddEdge("mapper", "reducer")
	mrg.graph.AddEdge("reducer", compose.END)
}

func (mrg *MapReduceGraph) Execute(inputs []string) (string, error) {
	runnable, err := mrg.graph.Compile(mrg.ctx)
	if err != nil {
		return "", fmt.Errorf("failed to compile map-reduce graph: %w", err)
	}
	
	return runnable.Invoke(mrg.ctx, inputs)
}

func (mrg *MapReduceGraph) GetWorkflowContext() *WorkflowContext {
	return mrg.wfCtx
}

// 3. Dynamic Routing Pattern
type DynamicRoutingGraph struct {
	graph *compose.Graph[string, string]
	model *openai.ChatModel
	ctx   context.Context
	wfCtx *WorkflowContext
}

func NewDynamicRoutingGraph(model *openai.ChatModel, ctx context.Context) *DynamicRoutingGraph {
	return &DynamicRoutingGraph{
		graph: compose.NewGraph[string, string](),
		model: model,
		ctx:   ctx,
		wfCtx: NewWorkflowContext("dynamic_routing_001"),
	}
}

func (drg *DynamicRoutingGraph) BuildDynamicRoutingGraph() {
	// Router Node: ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á
	router := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		drg.wfCtx.SetCurrentStep("router")
		
		fmt.Printf("üîÄ [Router] Analyzing input to determine routing\n")
		
		// ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á input
		var route string
		lowerInput := strings.ToLower(input)
		
		switch {
		case strings.Contains(lowerInput, "code") || strings.Contains(lowerInput, "programming") || strings.Contains(lowerInput, "function"):
			route = "code_analyzer"
		case strings.Contains(lowerInput, "business") || strings.Contains(lowerInput, "market") || strings.Contains(lowerInput, "strategy"):
			route = "business_analyzer"
		case strings.Contains(lowerInput, "technical") || strings.Contains(lowerInput, "system") || strings.Contains(lowerInput, "architecture"):
			route = "tech_analyzer"
		default:
			route = "general_analyzer"
		}
		
		result := fmt.Sprintf("ROUTE:%s|%s", route, input)
		
		taskResult := TaskResult{
			NodeName: "router",
			Input:    input,
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
			Metadata: map[string]interface{}{
				"selected_route": route,
			},
		}
		drg.wfCtx.AddResult("router", taskResult)
		
		fmt.Printf("‚û°Ô∏è [Router] Routing to: %s\n", route)
		return result, nil
	})

	// Code Analyzer
	codeAnalyzer := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		drg.wfCtx.SetCurrentStep("code_analyzer")
		
		// ‡πÅ‡∏¢‡∏Å route info ‡∏Å‡∏±‡∏ö actual input
		parts := strings.SplitN(input, "|", 2)
		if len(parts) != 2 || !strings.HasPrefix(parts[0], "ROUTE:code_analyzer") {
			return input, nil // ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤
		}
		
		actualInput := parts[1]
		fmt.Printf("üíª [CodeAnalyzer] Analyzing code-related content\n")
		
		messages := []*schema.Message{
			schema.SystemMessage("‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°"),
			schema.UserMessage(actualInput),
		}
		
		response, err := drg.model.Generate(ctx, messages)
		if err != nil {
			return "", err
		}
		
		result := fmt.Sprintf("üíª Code Analysis: %s", response.Content)
		
		taskResult := TaskResult{
			NodeName: "code_analyzer",
			Input:    actualInput,
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
		}
		drg.wfCtx.AddResult("code_analyzer", taskResult)
		
		return result, nil
	})

	// Business Analyzer
	businessAnalyzer := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		drg.wfCtx.SetCurrentStep("business_analyzer")
		
		parts := strings.SplitN(input, "|", 2)
		if len(parts) != 2 || !strings.HasPrefix(parts[0], "ROUTE:business_analyzer") {
			return input, nil
		}
		
		actualInput := parts[1]
		fmt.Printf("üìà [BusinessAnalyzer] Analyzing business content\n")
		
		messages := []*schema.Message{
			schema.SystemMessage("‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à ‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå"),
			schema.UserMessage(actualInput),
		}
		
		response, err := drg.model.Generate(ctx, messages)
		if err != nil {
			return "", err
		}
		
		result := fmt.Sprintf("üìà Business Analysis: %s", response.Content)
		
		taskResult := TaskResult{
			NodeName: "business_analyzer",
			Input:    actualInput,
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
		}
		drg.wfCtx.AddResult("business_analyzer", taskResult)
		
		return result, nil
	})

	// General Analyzer
	generalAnalyzer := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
		startTime := time.Now()
		drg.wfCtx.SetCurrentStep("general_analyzer")
		
		parts := strings.SplitN(input, "|", 2)
		actualInput := input
		if len(parts) == 2 && strings.HasPrefix(parts[0], "ROUTE:") {
			actualInput = parts[1]
		}
		
		fmt.Printf("üîç [GeneralAnalyzer] General content analysis\n")
		
		messages := []*schema.Message{
			schema.SystemMessage("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°"),
			schema.UserMessage(actualInput),
		}
		
		response, err := drg.model.Generate(ctx, messages)
		if err != nil {
			return "", err
		}
		
		result := fmt.Sprintf("üîç General Analysis: %s", response.Content)
		
		taskResult := TaskResult{
			NodeName: "general_analyzer",
			Input:    actualInput,
			Output:   result,
			Duration: time.Since(startTime),
			Success:  true,
		}
		drg.wfCtx.AddResult("general_analyzer", taskResult)
		
		return result, nil
	})

	// ‡πÄ‡∏û‡∏¥‡πà‡∏° nodes
	drg.graph.AddLambdaNode("router", router)
	drg.graph.AddLambdaNode("code_analyzer", codeAnalyzer)
	drg.graph.AddLambdaNode("business_analyzer", businessAnalyzer)
	drg.graph.AddLambdaNode("general_analyzer", generalAnalyzer)

	// ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° edges - dynamic routing
	drg.graph.AddEdge(compose.START, "router")
	drg.graph.AddEdge("router", "code_analyzer")
	drg.graph.AddEdge("router", "business_analyzer")
	drg.graph.AddEdge("router", "general_analyzer")
	drg.graph.AddEdge("code_analyzer", compose.END)
	drg.graph.AddEdge("business_analyzer", compose.END)
	drg.graph.AddEdge("general_analyzer", compose.END)
}

func (drg *DynamicRoutingGraph) Execute(input string) (string, error) {
	runnable, err := drg.graph.Compile(drg.ctx)
	if err != nil {
		return "", fmt.Errorf("failed to compile dynamic routing graph: %w", err)
	}
	
	return runnable.Invoke(drg.ctx, input)
}

func (drg *DynamicRoutingGraph) GetWorkflowContext() *WorkflowContext {
	return drg.wfCtx
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func runAdvancedGraphPatternsDemo() {
	// Load environment
	err := godotenv.Load()
	if err != nil {
		log.Fatal("Error loading .env file")
	}

	ctx := context.Background()
	apiKey := os.Getenv("OPENROUTER_API_KEY")
	if apiKey == "" {
		fmt.Println("Please set OPENROUTER_API_KEY environment variable")
		return
	}

	// ‡∏™‡∏£‡πâ‡∏≤‡∏á model
	config := &openai.ChatModelConfig{
		APIKey:  apiKey,
		BaseURL: "https://openrouter.ai/api/v1",
		Model:   "openai/gpt-3.5-turbo",
	}

	model, err := openai.NewChatModel(ctx, config)
	if err != nil {
		fmt.Printf("Error creating model: %v\n", err)
		return
	}

	fmt.Println("=== ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 9: Advanced Graph Patterns ===")
	fmt.Println("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Graph ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡πÉ‡∏ô Eino")
	fmt.Println()

	// === Demo 1: Fan-Out/Fan-In Pattern ===
	fmt.Println("üîÄ Demo 1: Fan-Out/Fan-In Pattern")
	
	fanOutFanInGraph := NewFanOutFanInGraph(model, ctx)
	fanOutFanInGraph.BuildFanOutFanInGraph()

	testInput := "Go ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏°‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ Google ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ microservices ‡πÅ‡∏•‡∏∞ cloud applications"

	fmt.Printf("Input: %s\n\n", testInput)
	
	result1, err := fanOutFanInGraph.Execute(testInput)
	if err != nil {
		fmt.Printf("Error: %v\n", err)
	} else {
		fmt.Printf("Result:\n%s\n", result1)
	}

	// ‡πÅ‡∏™‡∏î‡∏á workflow context
	wfCtx1 := fanOutFanInGraph.GetWorkflowContext()
	fmt.Printf("\nüìä Workflow Context:\n")
	wfJSON1, _ := json.MarshalIndent(wfCtx1, "", "  ")
	fmt.Printf("%s\n", wfJSON1)

	fmt.Println(strings.Repeat("=", 80))

	// === Demo 2: Map-Reduce Pattern ===
	fmt.Println("\nüó∫Ô∏è Demo 2: Map-Reduce Pattern")
	
	mapReduceGraph := NewMapReduceGraph(model, ctx)
	mapReduceGraph.BuildMapReduceGraph()

	testInputs := []string{
		"Go ‡∏°‡∏µ‡∏£‡∏∞‡∏ö‡∏ö garbage collection ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û",
		"Goroutines ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô concurrent programming ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô",
		"Go modules ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ dependencies",
		"Interface ‡πÉ‡∏ô Go ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô",
	}

	fmt.Printf("Inputs (%d items):\n", len(testInputs))
	for i, input := range testInputs {
		fmt.Printf("  %d. %s\n", i+1, input)
	}
	fmt.Println()
	
	result2, err := mapReduceGraph.Execute(testInputs)
	if err != nil {
		fmt.Printf("Error: %v\n", err)
	} else {
		fmt.Printf("Result:\n%s\n", result2)
	}

	// ‡πÅ‡∏™‡∏î‡∏á workflow context
	wfCtx2 := mapReduceGraph.GetWorkflowContext()
	fmt.Printf("\nüìä Map-Reduce Workflow:\n")
	for nodeName, result := range wfCtx2.Results {
		fmt.Printf("- %s: %v (success: %t)\n", nodeName, result.Duration, result.Success)
	}

	fmt.Println(strings.Repeat("=", 80))

	// === Demo 3: Dynamic Routing Pattern ===
	fmt.Println("\nüîÄ Demo 3: Dynamic Routing Pattern")
	
	dynamicGraph := NewDynamicRoutingGraph(model, ctx)
	dynamicGraph.BuildDynamicRoutingGraph()

	testCases := []string{
		"‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sorting array ‡πÉ‡∏ô Go",
		"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö startup",
		"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° microservices",
		"‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ meditation ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û",
	}

	for i, testCase := range testCases {
		fmt.Printf("\n--- Dynamic Routing Test %d ---\n", i+1)
		fmt.Printf("Input: %s\n", testCase)
		
		result3, err := dynamicGraph.Execute(testCase)
		if err != nil {
			fmt.Printf("Error: %v\n", err)
		} else {
			fmt.Printf("Result: %s\n", result3[:100]+"...")
		}
		
		// ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
		wfCtx3 := dynamicGraph.GetWorkflowContext()
		if routerResult, exists := wfCtx3.GetResult("router"); exists {
			if route, ok := routerResult.Metadata["selected_route"]; ok {
				fmt.Printf("üéØ Selected Route: %s\n", route)
			}
		}
	}

	fmt.Println("\n‚úÖ Advanced Graph Patterns Demo Complete!")
	fmt.Println("üéØ Key Patterns Demonstrated:")
	fmt.Println("   - Fan-Out/Fan-In: Parallel processing with aggregation")
	fmt.Println("   - Map-Reduce: Distributed processing pattern")
	fmt.Println("   - Dynamic Routing: Conditional execution paths")
	fmt.Println("   - Workflow Context: State management across patterns")
	fmt.Println("   - Task Result Tracking: Performance monitoring")
	fmt.Println("   - Pattern Composition: Combining multiple patterns")
}

func main() {
	runAdvancedGraphPatternsDemo()
}